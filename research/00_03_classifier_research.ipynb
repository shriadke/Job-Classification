{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Research\n",
    "\n",
    "### Purpose\n",
    "\n",
    "1. To generate/load the sentence embeddings in run-time or from stored location,\n",
    "2. Identify different classifier heads suitable for this classification task,\n",
    "3. Train and test classifier model,\n",
    "4. Evaluate/compare the performance on test data,\n",
    "5. Define and test the common functions necessary for actual prediction pipeline i.e. `predict()` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import pipeline, set_seed, AutoTokenizer, AutoModel\n",
    "from sentence_transformers import SentenceTransformer, models, InputExample, losses, evaluation, util\n",
    "from sentence_transformers.util import cos_sim, dot_score\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset, load_from_disk, load_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Common Functions for data, embedding processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_special_tokens(path=\"../data/raw/special_words.txt\"):\n",
    "    \"\"\" \n",
    "    This method returns list of special words to be removed from the text.\n",
    "    \n",
    "    Input: path: str --> Path to the word file\n",
    "\n",
    "    Output: : special_tokens: list[str] --> all words/special tokens to be removed\n",
    "    \"\"\"\n",
    "    special_tokens=[]\n",
    "    if not os.path.exists(path):\n",
    "        return []\n",
    "\n",
    "    with open(path, \"r\") as f:\n",
    "        special_tokens = f.readlines()\n",
    "    special_tokens = [line.rstrip('\\n') for line in special_tokens]\n",
    "    \n",
    "    return special_tokens\n",
    "\n",
    "def clean_text(text, stop_words=stopwords.words('english'), punct=string.punctuation, special_tokens=[]):\n",
    "        \"\"\" \n",
    "        This method returns cleaned String from an input string. \n",
    "        Removes stop words, punctuations, numbers and any special tokens given.\n",
    "        \n",
    "        Input:  text : str                  --> input string to be cleaned\n",
    "                stop_words : list[str]      --> (Optional) list of stop words to be removed from the text\n",
    "                punct : list[str]           --> (Optional) list of punctuations to be removed from the text\n",
    "                special_tokens : list[str]  --> (Optional) list of special words to be removed from the text\n",
    "\n",
    "        Output: text: string:  cleaned text\n",
    "        \"\"\"\n",
    "\n",
    "        text= text.lower()\n",
    "        \n",
    "        text = text.replace(\"\\n\",\" \")\n",
    "        \n",
    "        text = text.replace(r'[0-9]+', ' ')\n",
    "        text = text.replace(r'[^\\w\\s]', ' ')\n",
    "        text = text.replace(r'[^a-zA-Z]', ' ')\n",
    "        for p in punct:\n",
    "            text = text.replace(p,\" \") \n",
    "            \n",
    "        text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "        text = ' '.join([word for word in text.split() if word not in special_tokens])\n",
    "        text = ''.join([i for i in text if not i.isdigit()])\n",
    "        text = text.replace(r'\\s+', ' ')\n",
    "        text = ' '.join([i for i in text.split() if len(i)>1])\n",
    "        \n",
    "        text = text.replace(r'\\s+', ' ')\n",
    "        return text\n",
    "\n",
    "def get_clean_job_str(job_title, job_post):\n",
    "    \"\"\" \n",
    "    This method returns cleaned Job Posting from Job Title and Job String. \n",
    "    Appends title and body tokens and concatenates the two.\n",
    "    \n",
    "    Input: Job Title Raw : string\n",
    "            Job Body Raw : string\n",
    "    Output: job_str: string:  cleaned and concatenated job details\n",
    "    \"\"\"\n",
    "    title_token = \"[TTL] \"\n",
    "    body_token = \" [DESC] \"\n",
    "\n",
    "    job_title = clean_text(job_title, special_tokens=get_special_tokens())\n",
    "    job_post = clean_text(job_post, special_tokens=get_special_tokens())\n",
    "\n",
    "    job_str = title_token + job_title + body_token + job_post\n",
    "\n",
    "    return job_str\n",
    "def get_all_onets(onet_data_path=\"../data/raw/All_Occupations.csv\"):\n",
    "    \"\"\" \n",
    "    This method returns list of all ONETs available on the official site\n",
    "    \n",
    "    Input: path: str -->  (Optional) Path to the onet csv file\n",
    "\n",
    "    Output: : all_onets_original: list[str] --> all ONETs available\n",
    "    \"\"\"\n",
    "    all_occupations_df = pd.read_csv(onet_data_path)\n",
    "    all_onets_original = all_occupations_df.Occupation.to_list()\n",
    "    return all_onets_original\n",
    "\n",
    "def get_onet_dicts(all_onets_original=get_all_onets()):\n",
    "    \"\"\" \n",
    "    This method returns 2 dictionaries used to map standard ONET Names to string IDs. \n",
    "    \n",
    "    Input: all_onets_original: list[str] --> (Optional) list of all ONETs\n",
    "\n",
    "    Output: : id_to_onet_dict: dict[str, str] --> standard mapping of string id to ONETs --> \"id\" : \"ONET_NAME\"\n",
    "              onet_to_id_dict: dict[str, str] --> standard mapping of ONETs to string id --> \"ONET_NAME\" : \"id\"\n",
    "    \"\"\"\n",
    "    id_to_onet_dict = {str(id):onet for id, onet in enumerate(all_onets_original)}\n",
    "    onet_to_id_dict = {onet:id for id,onet in id_to_onet_dict.items()}\n",
    "    return id_to_onet_dict, onet_to_id_dict\n",
    "\n",
    "def get_embd(input_docs, model=None, model_ckpt=None, save_embd=False, save_path=None):\n",
    "    \"\"\" \n",
    "    This method computes embedding of the given string or list of strings using the given SBERT model. \n",
    "    \n",
    "    Input: input_docs: str or list[str] --> list of input string. Can be a single string which will be converted to a list.\n",
    "           model: SentenceTransformers() --> (Optional) pre-trained SBERT model, if None, checks for path \n",
    "           model_ckpt: str --> (Optional) pre-trained SBERT model checkpoint path, if None, loads basic SBERT from HF library \n",
    "           save_embd: Boolean --> (Optional) Flag to save computed embeddings.\n",
    "           save_path: str --> (Optional) Path to save computed embeddings. If empty, new path will be created\n",
    "\n",
    "    Output: simple_embd: numpy.ndarray (len(input), embd_size) --> array of Computed sentence embeddings. \n",
    "    \"\"\"\n",
    "\n",
    "    if not input_docs:\n",
    "        return None\n",
    "    if not isinstance(input_docs, list):\n",
    "        print(\"convert string to list\")\n",
    "        input_docs = [input_docs]       \n",
    "\n",
    "    if model:\n",
    "        print(\"loading model as it is\")\n",
    "        sbert_model = model\n",
    "    elif model_ckpt:\n",
    "        print(\"loading model from ckpt\")\n",
    "        if not os.path.exists(model_ckpt):\n",
    "            model_ckpt = \"shriadke/adept-job-msmarco-distilbert-base-v4\"\n",
    "        print(\"loading model from ckpt: \", model_ckpt)\n",
    "        sbert_model = SentenceTransformer(model_ckpt)\n",
    "    else:\n",
    "        print(\"loading HF base model\")\n",
    "        sbert_model = SentenceTransformer(\"msmarco-distilbert-base-v4\")\n",
    "    \n",
    "    simple_embd = sbert_model.encode(input_docs, show_progress_bar=True)\n",
    "    \n",
    "    if save_embd and save_path:\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path, exist_ok=True)\n",
    "            #os.chmod(save_path+\"embd.pkl\", 0o777)\n",
    "        with open(save_path+\"embd.pkl\", \"wb\") as fOut:\n",
    "            print(\"lenght of docs: \", len(input_docs))\n",
    "            print(\"lenght of embd: \", len(simple_embd))\n",
    "            pickle.dump({'input': input_docs, 'embeddings': simple_embd}, fOut, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return simple_embd\n",
    "\n",
    "def get_onet_embeddings(model=None, model_ckpt=None, onet_embd_path=None, save_embd=False, save_path=\"./data/processed/embeddings/onet/\"):\n",
    "    \"\"\" \n",
    "    This method computes embedding for all ONETs available. \n",
    "    \n",
    "    Input: model: SentenceTransformers() --> (Optional) pre-trained SBERT model, if None, checks for path \n",
    "           model_ckpt: str --> (Optional) pre-trained SBERT model checkpoint path, if None, loads basic SBERT from HF library \n",
    "           onet_embd_path: str --> (Optional) Path to load computed embeddings from pickle. If empty, Embeddings will be computed from scratch. \n",
    "           save_embd: Boolean --> (Optional) Flag to save computed embeddings.\n",
    "           save_path: str --> (Optional) Path to save computed embeddings. If empty, new path will be created\n",
    "\n",
    "    Output: onet_embd_df: pandas.DataFrame --> Dataframe with 2 columns:[\"ONET_NAME\", \"ONET_EMBD\"] \n",
    "                                               Computed sentence embeddings can be stored as key, val pair. \n",
    "    \"\"\"\n",
    "    onet_embd_df = pd.DataFrame(columns=[\"ONET_NAME\", \"ONET_EMBD\"])\n",
    "    \n",
    "    if not onet_embd_path:\n",
    "        # Create onet embeddings from all onet data\n",
    "        # Get list of all ONETs\n",
    "        all_onets_original = get_all_onets()\n",
    "\n",
    "        # Compute Embeddings of the entire list \n",
    "        simple_embd = get_embd(all_onets_original, model=model, model_ckpt=model_ckpt, save_embd=save_embd, save_path=save_path)\n",
    "\n",
    "        # Save Embds as dataframe\n",
    "        onet_embd_df[\"ONET_NAME\"] = pd.Series(all_onets_original)\n",
    "        onet_embd_df[\"ONET_EMBD\"] = pd.Series([arr for arr in simple_embd])\n",
    "        \n",
    "    elif os.path.exists(onet_embd_path):\n",
    "        #Load sentences & embeddings from disc\n",
    "        with open(onet_embd_path, \"rb\") as fIn:\n",
    "            stored_data = pickle.load(fIn)\n",
    "            onet_embd_df[\"ONET_NAME\"] = stored_data['input']\n",
    "            onet_embd_df[\"ONET_EMBD\"] = pd.Series([arr for arr in stored_data['embeddings']])\n",
    "    \n",
    "    print(\"Total ONETs available: \",len(onet_embd_df))\n",
    "    return onet_embd_df\n",
    "\n",
    "def get_job_embed_df_from_df(job_df=None,model=None, model_ckpt=None, job_embd_path=None, save_embd=False, save_path=\"./data/processed/embeddings/job/\"):\n",
    "    \"\"\" \n",
    "    This method computes embedding for all ONETs available. \n",
    "    \n",
    "    Input: job_df: pandas.DataFrame --> (Optional) Raw job data Dataframe with at least 2 columns:[\"TITLE_RAW\", \"BODY\"], if empty, loads precomputed.\n",
    "           model: SentenceTransformers() --> (Optional) pre-trained SBERT model, if None, checks for path \n",
    "           model_ckpt: str --> (Optional) pre-trained SBERT model checkpoint path, if None, loads basic SBERT from HF library \n",
    "           job_embd_path: str --> (Optional) Path to load computed embeddings from pickle. If empty, Embeddings will be computed from scratch. \n",
    "           save_embd: Boolean --> (Optional) Flag to save computed embeddings.\n",
    "           save_path: str --> (Optional) Path to save computed embeddings. If empty, new path will be created\n",
    "\n",
    "    Output: onet_embd_df: pandas.DataFrame --> Dataframe with 2 columns:[\"ONET_NAME\", \"ONET_EMBD\"] \n",
    "                                               Computed sentence embeddings can be stored as key, val pair. \n",
    "    \"\"\"\n",
    "    if job_df is None:\n",
    "        print(\"Path to Job DF Given\")\n",
    "        job_df = pd.DataFrame(columns=[\"TITLE_RAW\",\"BODY\", \"CLEANED_JOB\", \"JOB_EMBD\"])\n",
    "        # load embeddings from stored DF embeddings\n",
    "        if os.path.exists(job_embd_path):\n",
    "            #Load sentences & embeddings from disc\n",
    "            with open(job_embd_path, \"rb\") as fIn:\n",
    "                stored_data = pickle.load(fIn)\n",
    "                # Loads cleaned job str and its embeddings\n",
    "                job_df[\"CLEANED_JOB\"] = stored_data['input']\n",
    "                job_df[\"JOB_EMBD\"] = pd.Series([arr for arr in stored_data['embeddings']])\n",
    "                job_df[\"TITLE_RAW\"] = job_df[\"CLEANED_JOB\"].apply(lambda x:x[6:x.find(\" [DESC] \")])\n",
    "                job_df[\"BODY\"] = job_df[\"CLEANED_JOB\"].apply(lambda x:x[x.find(\" [DESC] \")+1:])\n",
    "        else:\n",
    "            print(\"Path to Job DF does not exists\")\n",
    "            return job_df\n",
    "    elif len(job_df) > 0:\n",
    "        # DF present, compute from Raw DF\n",
    "        if not (\"TITLE_RAW\" in job_df.columns and \"BODY\" in job_df.columns):\n",
    "            print(\"Incomplete DataFrame, please try again\")\n",
    "            return None\n",
    "        if not \"CLEANED_JOB\" in job_df.columns:\n",
    "            job_df[\"CLEANED_JOB\"] = job_df.apply(lambda x:get_clean_job_str(x[\"TITLE_RAW\"], x[\"BODY\"]), axis=1)\n",
    "        \n",
    "        simple_embd = get_embd(job_df[\"CLEANED_JOB\"].to_list(), model=model, model_ckpt=model_ckpt, save_embd=save_embd, save_path=str(save_path)+str(len(job_df))+\"/\")\n",
    "\n",
    "        job_df[\"JOB_EMBD\"] = pd.Series([arr for arr in simple_embd])\n",
    "    else:\n",
    "        print(\"Unexpected Input Job DF, please try again\")\n",
    "    \n",
    "    print(\"Total Jobs available: \",len(job_df)) \n",
    "    return job_df\n",
    "\n",
    "def get_job_embd_df_frm_title_body(job_title, job_body, model_ckpt=None):\n",
    "    job_df = pd.DataFrame({ \"TITLE_RAW\" : [job_title],\n",
    "                            \"BODY\"      : [job_body], })\n",
    "                            #\"CLEANED_JOB\": get_clean_job_str(job_title, job_body)\n",
    "    job_df = get_job_embed_df_from_df(job_df=job_df, model_ckpt=None)\n",
    "\n",
    "    return job_df  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Preprocessed embeddings for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "temp_train_df = pd.read_csv(\"../artifacts/data_ingestion/raw_train/train_data.csv\")\n",
    "temp_train_df = temp_train_df.drop([\"ID\", \"POSTED\",\"ONET\"], axis=1)\n",
    "temp_train_df.head()\n",
    "id_to_onet_dict, onet_to_id_dict = get_onet_dicts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to Job DF Given\n",
      "Total Jobs available:  17927\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE_RAW</th>\n",
       "      <th>BODY</th>\n",
       "      <th>CLEANED_JOB</th>\n",
       "      <th>JOB_EMBD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>executive meeting manager</td>\n",
       "      <td>[DESC] executive meeting manager marriott la j...</td>\n",
       "      <td>[TTL] executive meeting manager [DESC] executi...</td>\n",
       "      <td>[-0.8965845, 0.21626818, 0.4062995, 0.25944906...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rehabilitation technician outpatient rehab fle...</td>\n",
       "      <td>[DESC] rehabilitation technician outpatient re...</td>\n",
       "      <td>[TTL] rehabilitation technician outpatient reh...</td>\n",
       "      <td>[-0.3449566, -0.01683965, -0.33390927, -0.0695...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>office bookkeeping assistant</td>\n",
       "      <td>[DESC] office bookkeeping assistant santa barb...</td>\n",
       "      <td>[TTL] office bookkeeping assistant [DESC] offi...</td>\n",
       "      <td>[-0.4091166, 1.4821604, 0.5247243, -0.10980953...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>administrative support coordinator va remote</td>\n",
       "      <td>[DESC] find jobs administrative support coordi...</td>\n",
       "      <td>[TTL] administrative support coordinator va re...</td>\n",
       "      <td>[-0.8193301, 0.6742436, 0.6131675, -0.277765, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>receptionist administrative assistant</td>\n",
       "      <td>[DESC] receptionist administrative assistant b...</td>\n",
       "      <td>[TTL] receptionist administrative assistant [D...</td>\n",
       "      <td>[-0.3198364, 1.0830945, 0.35040185, -0.0614275...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           TITLE_RAW  \\\n",
       "0                          executive meeting manager   \n",
       "1  rehabilitation technician outpatient rehab fle...   \n",
       "2                       office bookkeeping assistant   \n",
       "3       administrative support coordinator va remote   \n",
       "4              receptionist administrative assistant   \n",
       "\n",
       "                                                BODY  \\\n",
       "0  [DESC] executive meeting manager marriott la j...   \n",
       "1  [DESC] rehabilitation technician outpatient re...   \n",
       "2  [DESC] office bookkeeping assistant santa barb...   \n",
       "3  [DESC] find jobs administrative support coordi...   \n",
       "4  [DESC] receptionist administrative assistant b...   \n",
       "\n",
       "                                         CLEANED_JOB  \\\n",
       "0  [TTL] executive meeting manager [DESC] executi...   \n",
       "1  [TTL] rehabilitation technician outpatient reh...   \n",
       "2  [TTL] office bookkeeping assistant [DESC] offi...   \n",
       "3  [TTL] administrative support coordinator va re...   \n",
       "4  [TTL] receptionist administrative assistant [D...   \n",
       "\n",
       "                                            JOB_EMBD  \n",
       "0  [-0.8965845, 0.21626818, 0.4062995, 0.25944906...  \n",
       "1  [-0.3449566, -0.01683965, -0.33390927, -0.0695...  \n",
       "2  [-0.4091166, 1.4821604, 0.5247243, -0.10980953...  \n",
       "3  [-0.8193301, 0.6742436, 0.6131675, -0.277765, ...  \n",
       "4  [-0.3198364, 1.0830945, 0.35040185, -0.0614275...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get stored data frame along with embeddings\n",
    "job_df = get_job_embed_df_from_df(job_embd_path=\"data/processed/embeddings/job/custom_model_1/train/17927/embd.pkl\")\n",
    "job_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE_RAW</th>\n",
       "      <th>BODY</th>\n",
       "      <th>ONET_NAME</th>\n",
       "      <th>CLEANED_JOB</th>\n",
       "      <th>JOB_EMBD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Executive Meeting Manager</td>\n",
       "      <td>Executive Meeting Manager Marriott La Jolla - ...</td>\n",
       "      <td>Meeting, Convention, and Event Planners</td>\n",
       "      <td>[TTL] executive meeting manager [DESC] executi...</td>\n",
       "      <td>[-0.8965845, 0.21626818, 0.4062995, 0.25944906...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rehabilitation Technician-Outpatient Rehab-Fle...</td>\n",
       "      <td>Rehabilitation Technician-Outpatient Rehab-Fle...</td>\n",
       "      <td>Occupational Therapy Aides</td>\n",
       "      <td>[TTL] rehabilitation technician outpatient reh...</td>\n",
       "      <td>[-0.3449566, -0.01683965, -0.33390927, -0.0695...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Office/Bookkeeping Assistant</td>\n",
       "      <td>Office/Bookkeeping Assistant\\nSanta Barbara, C...</td>\n",
       "      <td>Office Clerks, General</td>\n",
       "      <td>[TTL] office bookkeeping assistant [DESC] offi...</td>\n",
       "      <td>[-0.4091166, 1.4821604, 0.5247243, -0.10980953...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Administrative Support Coordinator - VA - (REM...</td>\n",
       "      <td>Find Jobs Administrative Support Coordinator -...</td>\n",
       "      <td>Secretaries and Administrative Assistants, Exc...</td>\n",
       "      <td>[TTL] administrative support coordinator va re...</td>\n",
       "      <td>[-0.8193301, 0.6742436, 0.6131675, -0.277765, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Receptionist/Administrative Assistant</td>\n",
       "      <td>Receptionist/Administrative Assistant Burgess ...</td>\n",
       "      <td>Secretaries and Administrative Assistants, Exc...</td>\n",
       "      <td>[TTL] receptionist administrative assistant [D...</td>\n",
       "      <td>[-0.3198364, 1.0830945, 0.35040185, -0.0614275...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           TITLE_RAW  \\\n",
       "0                          Executive Meeting Manager   \n",
       "1  Rehabilitation Technician-Outpatient Rehab-Fle...   \n",
       "2                       Office/Bookkeeping Assistant   \n",
       "3  Administrative Support Coordinator - VA - (REM...   \n",
       "4              Receptionist/Administrative Assistant   \n",
       "\n",
       "                                                BODY  \\\n",
       "0  Executive Meeting Manager Marriott La Jolla - ...   \n",
       "1  Rehabilitation Technician-Outpatient Rehab-Fle...   \n",
       "2  Office/Bookkeeping Assistant\\nSanta Barbara, C...   \n",
       "3  Find Jobs Administrative Support Coordinator -...   \n",
       "4  Receptionist/Administrative Assistant Burgess ...   \n",
       "\n",
       "                                           ONET_NAME  \\\n",
       "0            Meeting, Convention, and Event Planners   \n",
       "1                         Occupational Therapy Aides   \n",
       "2                             Office Clerks, General   \n",
       "3  Secretaries and Administrative Assistants, Exc...   \n",
       "4  Secretaries and Administrative Assistants, Exc...   \n",
       "\n",
       "                                         CLEANED_JOB  \\\n",
       "0  [TTL] executive meeting manager [DESC] executi...   \n",
       "1  [TTL] rehabilitation technician outpatient reh...   \n",
       "2  [TTL] office bookkeeping assistant [DESC] offi...   \n",
       "3  [TTL] administrative support coordinator va re...   \n",
       "4  [TTL] receptionist administrative assistant [D...   \n",
       "\n",
       "                                            JOB_EMBD  \n",
       "0  [-0.8965845, 0.21626818, 0.4062995, 0.25944906...  \n",
       "1  [-0.3449566, -0.01683965, -0.33390927, -0.0695...  \n",
       "2  [-0.4091166, 1.4821604, 0.5247243, -0.10980953...  \n",
       "3  [-0.8193301, 0.6742436, 0.6131675, -0.277765, ...  \n",
       "4  [-0.3198364, 1.0830945, 0.35040185, -0.0614275...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_train_df[\"CLEANED_JOB\"] = job_df[\"CLEANED_JOB\"]\n",
    "temp_train_df[\"JOB_EMBD\"] = job_df[\"JOB_EMBD\"]\n",
    "temp_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data for classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE_RAW</th>\n",
       "      <th>BODY</th>\n",
       "      <th>ONET_NAME</th>\n",
       "      <th>CLEANED_JOB</th>\n",
       "      <th>JOB_EMBD</th>\n",
       "      <th>ONET_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Executive Meeting Manager</td>\n",
       "      <td>Executive Meeting Manager Marriott La Jolla - ...</td>\n",
       "      <td>Meeting, Convention, and Event Planners</td>\n",
       "      <td>[TTL] executive meeting manager [DESC] executi...</td>\n",
       "      <td>[-0.8965845, 0.21626818, 0.4062995, 0.25944906...</td>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rehabilitation Technician-Outpatient Rehab-Fle...</td>\n",
       "      <td>Rehabilitation Technician-Outpatient Rehab-Fle...</td>\n",
       "      <td>Occupational Therapy Aides</td>\n",
       "      <td>[TTL] rehabilitation technician outpatient reh...</td>\n",
       "      <td>[-0.3449566, -0.01683965, -0.33390927, -0.0695...</td>\n",
       "      <td>675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Office/Bookkeeping Assistant</td>\n",
       "      <td>Office/Bookkeeping Assistant\\nSanta Barbara, C...</td>\n",
       "      <td>Office Clerks, General</td>\n",
       "      <td>[TTL] office bookkeeping assistant [DESC] offi...</td>\n",
       "      <td>[-0.4091166, 1.4821604, 0.5247243, -0.10980953...</td>\n",
       "      <td>678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Administrative Support Coordinator - VA - (REM...</td>\n",
       "      <td>Find Jobs Administrative Support Coordinator -...</td>\n",
       "      <td>Secretaries and Administrative Assistants, Exc...</td>\n",
       "      <td>[TTL] administrative support coordinator va re...</td>\n",
       "      <td>[-0.8193301, 0.6742436, 0.6131675, -0.277765, ...</td>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Receptionist/Administrative Assistant</td>\n",
       "      <td>Receptionist/Administrative Assistant Burgess ...</td>\n",
       "      <td>Secretaries and Administrative Assistants, Exc...</td>\n",
       "      <td>[TTL] receptionist administrative assistant [D...</td>\n",
       "      <td>[-0.3198364, 1.0830945, 0.35040185, -0.0614275...</td>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           TITLE_RAW  \\\n",
       "0                          Executive Meeting Manager   \n",
       "1  Rehabilitation Technician-Outpatient Rehab-Fle...   \n",
       "2                       Office/Bookkeeping Assistant   \n",
       "3  Administrative Support Coordinator - VA - (REM...   \n",
       "4              Receptionist/Administrative Assistant   \n",
       "\n",
       "                                                BODY  \\\n",
       "0  Executive Meeting Manager Marriott La Jolla - ...   \n",
       "1  Rehabilitation Technician-Outpatient Rehab-Fle...   \n",
       "2  Office/Bookkeeping Assistant\\nSanta Barbara, C...   \n",
       "3  Find Jobs Administrative Support Coordinator -...   \n",
       "4  Receptionist/Administrative Assistant Burgess ...   \n",
       "\n",
       "                                           ONET_NAME  \\\n",
       "0            Meeting, Convention, and Event Planners   \n",
       "1                         Occupational Therapy Aides   \n",
       "2                             Office Clerks, General   \n",
       "3  Secretaries and Administrative Assistants, Exc...   \n",
       "4  Secretaries and Administrative Assistants, Exc...   \n",
       "\n",
       "                                         CLEANED_JOB  \\\n",
       "0  [TTL] executive meeting manager [DESC] executi...   \n",
       "1  [TTL] rehabilitation technician outpatient reh...   \n",
       "2  [TTL] office bookkeeping assistant [DESC] offi...   \n",
       "3  [TTL] administrative support coordinator va re...   \n",
       "4  [TTL] receptionist administrative assistant [D...   \n",
       "\n",
       "                                            JOB_EMBD  ONET_ID  \n",
       "0  [-0.8965845, 0.21626818, 0.4062995, 0.25944906...      613  \n",
       "1  [-0.3449566, -0.01683965, -0.33390927, -0.0695...      675  \n",
       "2  [-0.4091166, 1.4821604, 0.5247243, -0.10980953...      678  \n",
       "3  [-0.8193301, 0.6742436, 0.6131675, -0.277765, ...      855  \n",
       "4  [-0.3198364, 1.0830945, 0.35040185, -0.0614275...      855  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert O*NETS to ids as prediction classes \n",
    "temp_train_df[\"ONET_ID\"] = temp_train_df[\"ONET_NAME\"].apply(lambda x:int(onet_to_id_dict[x]))\n",
    "temp_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data into train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= temp_train_df[\"JOB_EMBD\"].to_list()\n",
    "y = temp_train_df[\"ONET_ID\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(X,y ,test_size = 0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of classes :  1017\n"
     ]
    }
   ],
   "source": [
    "all_classes = list(range(0,len(onet_to_id_dict)))\n",
    "print(\"No of classes : \", len(all_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and save LR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 740 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=20, random_state=42, solver=&#x27;sag&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=20, random_state=42, solver=&#x27;sag&#x27;, verbose=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=20, random_state=42, solver='sag', verbose=1)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = LogisticRegression(solver = 'sag' , max_iter =20, verbose=1, random_state=42)\n",
    "model1.fit(xtrain , ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./classifier/LR/model_20_sag.pkl\", \"wb\") as fOut:\n",
    "    pickle.dump(model1, fOut, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check performance on Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.7112597547380156\n",
      "top 1 accuracy :  0.7112597547380156\n",
      "top 5 accuracy :  0.8807134894091416\n",
      "top 10 accuracy :  0.9141583054626533\n"
     ]
    }
   ],
   "source": [
    "y_pred = loaded_model.predict(xtest)\n",
    "\n",
    "acc=metrics.accuracy_score(ytest,y_pred)\n",
    "print(\"accuracy : \",acc)\n",
    "\n",
    "# Convert available classes to all classes.\n",
    "# This is due to the missing output classes from training. This skews/ommits the missing class ids and needs to be fixed.\n",
    "all_classes = np.array(sorted(all_classes))\n",
    "# Get the probabilities for learnt classes\n",
    "prob = loaded_model.predict_proba(xtest)\n",
    "# Create the result matrix, where all values are initially zero\n",
    "new_prob = np.zeros((prob.shape[0], all_classes.size))\n",
    "# Set the columns corresponding to clf.classes_\n",
    "new_prob[:, all_classes.searchsorted(loaded_model.classes_)] = prob\n",
    "\n",
    "# Calculate top_k accuracies\n",
    "k_acc = metrics.top_k_accuracy_score(ytest,new_prob,k=1, labels=all_classes)\n",
    "print(\"top 1 accuracy : \",k_acc)\n",
    "k_acc = metrics.top_k_accuracy_score(ytest,new_prob,k=5, labels=all_classes)\n",
    "print(\"top 5 accuracy : \",k_acc)\n",
    "k_acc = metrics.top_k_accuracy_score(ytest,new_prob,k=10, labels=all_classes)\n",
    "print(\"top 10 accuracy : \",k_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Accountants and Auditors ['Accountants and Auditors', 'Sales Representatives, Wholesale and Manufacturing, Except Technical and Scientific Products', 'Information Technology Project Managers', 'Sales Managers', 'Public Relations Managers']\n",
      "0 0 [0]\n",
      "1 Occupational Health and Safety Specialists ['General and Operations Managers', 'Managers, All Other', 'Occupational Health and Safety Specialists', 'Training and Development Specialists', 'Emergency Management Directors']\n",
      "1 672 [2]\n",
      "2 Automotive Service Technicians and Mechanics ['Environmental Science and Protection Technicians, Including Health', 'Janitors and Cleaners, Except Maids and Housekeeping Cleaners', 'Heating, Air Conditioning, and Refrigeration Mechanics and Installers', 'Landscaping and Groundskeeping Workers', 'Maintenance and Repair Workers, General']\n",
      "3 Human Resources Specialists ['Human Resources Specialists', 'Public Relations Specialists', 'Market Research Analysts and Marketing Specialists', 'Document Management Specialists', 'Search Marketing Strategists']\n",
      "3 493 [0]\n",
      "4 Recreation Workers ['Recreation Workers', 'Managers, All Other', 'Automotive Service Technicians and Mechanics', 'First-Line Supervisors of Food Preparation and Serving Workers', 'First-Line Supervisors of Non-Retail Sales Workers']\n",
      "4 814 [0]\n",
      "5 Social Science Research Assistants ['Operations Research Analysts', 'Social Science Research Assistants', 'Unclassified', 'Financial and Investment Analysts', 'Biologists']\n",
      "5 882 [1]\n",
      "6 Financial Managers ['Accountants and Auditors', 'Tax Examiners and Collectors, and Revenue Agents', 'Managers, All Other', 'First-Line Supervisors of Office and Administrative Support Workers', 'Tax Preparers']\n",
      "7 Middle School Teachers, Except Special and Career/Technical Education ['Special Education Teachers, Middle School', 'Postsecondary Teachers, All Other', 'Health Education Specialists', 'Teaching Assistants, Preschool, Elementary, Middle, and Secondary School, Except Special Education', 'Elementary School Teachers, Except Special Education']\n",
      "8 Secondary School Teachers, Except Special and Career/Technical Education ['Secondary School Teachers, Except Special and Career/Technical Education', 'Middle School Teachers, Except Special and Career/Technical Education', 'Postsecondary Teachers, All Other', 'Mathematical Science Teachers, Postsecondary', 'Elementary School Teachers, Except Special Education']\n",
      "8 854 [0]\n",
      "9 Managers, All Other ['Managers, All Other', 'First-Line Supervisors of Production and Operating Workers', 'First-Line Supervisors of Mechanics, Installers, and Repairers', 'Industrial Production Managers', 'First-Line Supervisors of Food Preparation and Serving Workers']\n",
      "9 576 [0]\n"
     ]
    }
   ],
   "source": [
    "# Sample Output of prediction\n",
    "# data_id, Actual O*NET label, Predicted list of top 5 O*NETs\n",
    "# data_id, Actual O*NET ID, Index/ Rank at which it is found in predicted list\n",
    "\n",
    "for i in range(10):\n",
    "    preds_idx = np.argsort(new_prob[i])[::-1][:5]\n",
    "    print(i, id_to_onet_dict[str(ytest[i])], [id_to_onet_dict[str(idx)] for idx in preds_idx])\n",
    "    if ytest[i] in preds_idx:\n",
    "        print(i, ytest[i], np.where(preds_idx == ytest[i])[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of LR Model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to Job DF Given\n",
      "Total Jobs available:  19394\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE_RAW</th>\n",
       "      <th>BODY</th>\n",
       "      <th>ONET_NAME</th>\n",
       "      <th>CLEANED_JOB</th>\n",
       "      <th>JOB_EMBD</th>\n",
       "      <th>ONET_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grocery Order Writer (Buyer / Inventory Replen...</td>\n",
       "      <td>Grocery Order Writer (Buyer / Inventory Replen...</td>\n",
       "      <td>Purchasing Agents, Except Wholesale, Retail, a...</td>\n",
       "      <td>[TTL] grocery order writer buyer inventory rep...</td>\n",
       "      <td>[-0.98015654, -0.2370125, -0.054709036, 0.5909...</td>\n",
       "      <td>794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Superintendent</td>\n",
       "      <td>Apply to this job. \\nThink you're the perfect ...</td>\n",
       "      <td>Education Administrators, Kindergarten through...</td>\n",
       "      <td>[TTL] superintendent [DESC] think perfect cand...</td>\n",
       "      <td>[-0.7707803, 0.068227395, -0.3073499, 0.680984...</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Software Developer IV</td>\n",
       "      <td>Software Developer IV\\nJob Locations\\nUS-NE-Om...</td>\n",
       "      <td>Software Developers</td>\n",
       "      <td>[TTL] software developer iv [DESC] software de...</td>\n",
       "      <td>[-0.62012154, 0.47546214, 0.3680548, 0.3727675...</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Auto Glass Technician</td>\n",
       "      <td>Auto Glass Technician Gerber Collision &amp; Glass...</td>\n",
       "      <td>Automotive Service Technicians and Mechanics</td>\n",
       "      <td>[TTL] auto glass technician [DESC] auto glass ...</td>\n",
       "      <td>[0.7393341, 0.5710749, 0.3004027, 0.2613186, 0...</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Food and Beverage Operations Manager</td>\n",
       "      <td>Food and Beverage Operations Manager Wavetroni...</td>\n",
       "      <td>Food Service Managers</td>\n",
       "      <td>[TTL] food beverage operations manager [DESC] ...</td>\n",
       "      <td>[-0.7466557, 0.78241795, -0.22036402, -0.59654...</td>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           TITLE_RAW  \\\n",
       "0  Grocery Order Writer (Buyer / Inventory Replen...   \n",
       "1                                     Superintendent   \n",
       "2                              Software Developer IV   \n",
       "3                              Auto Glass Technician   \n",
       "4               Food and Beverage Operations Manager   \n",
       "\n",
       "                                                BODY  \\\n",
       "0  Grocery Order Writer (Buyer / Inventory Replen...   \n",
       "1  Apply to this job. \\nThink you're the perfect ...   \n",
       "2  Software Developer IV\\nJob Locations\\nUS-NE-Om...   \n",
       "3  Auto Glass Technician Gerber Collision & Glass...   \n",
       "4  Food and Beverage Operations Manager Wavetroni...   \n",
       "\n",
       "                                           ONET_NAME  \\\n",
       "0  Purchasing Agents, Except Wholesale, Retail, a...   \n",
       "1  Education Administrators, Kindergarten through...   \n",
       "2                                Software Developers   \n",
       "3       Automotive Service Technicians and Mechanics   \n",
       "4                              Food Service Managers   \n",
       "\n",
       "                                         CLEANED_JOB  \\\n",
       "0  [TTL] grocery order writer buyer inventory rep...   \n",
       "1  [TTL] superintendent [DESC] think perfect cand...   \n",
       "2  [TTL] software developer iv [DESC] software de...   \n",
       "3  [TTL] auto glass technician [DESC] auto glass ...   \n",
       "4  [TTL] food beverage operations manager [DESC] ...   \n",
       "\n",
       "                                            JOB_EMBD  ONET_ID  \n",
       "0  [-0.98015654, -0.2370125, -0.054709036, 0.5909...      794  \n",
       "1  [-0.7707803, 0.068227395, -0.3073499, 0.680984...      277  \n",
       "2  [-0.62012154, 0.47546214, 0.3680548, 0.3727675...      889  \n",
       "3  [0.7393341, 0.5710749, 0.3004027, 0.2613186, 0...       76  \n",
       "4  [-0.7466557, 0.78241795, -0.22036402, -0.59654...      404  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_test_df = pd.read_csv(\"../artifacts/data_ingestion/raw_train/train_data.csv\")\n",
    "temp_test_df = temp_test_df.drop([\"ID\", \"POSTED\",\"ONET\"], axis=1)\n",
    "\n",
    "# Load Precomputed test data embeddings\n",
    "test_job_df = get_job_embed_df_from_df(job_embd_path=\"../data/processed/embeddings/job/custom_model_1/test/19394/embd.pkl\")\n",
    "\n",
    "temp_test_df[\"CLEANED_JOB\"] = test_job_df[\"CLEANED_JOB\"]\n",
    "temp_test_df[\"JOB_EMBD\"] = test_job_df[\"JOB_EMBD\"]\n",
    "id_to_onet_dict, onet_to_id_dict = get_onet_dicts()\n",
    "temp_test_df[\"ONET_ID\"] = temp_test_df[\"ONET_NAME\"].apply(lambda x:int(onet_to_id_dict[x]))\n",
    "temp_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and labels for test data\n",
    "X= temp_test_df[\"JOB_EMBD\"].to_list()\n",
    "y = temp_test_df[\"ONET_ID\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.6844900484685985\n",
      "top 1 accuracy :  0.6844900484685985\n",
      "top 5 accuracy :  0.8764050737341446\n",
      "top 10 accuracy :  0.9127565226358668\n"
     ]
    }
   ],
   "source": [
    "# model 1 metrics\n",
    "with open(\"classifier/LR/model_20_sag.pkl\", \"rb\") as fIn:\n",
    "    loaded_model = pickle.load(fIn)\n",
    " \n",
    "y_pred = loaded_model.predict(X)\n",
    "#print(metrics.classification_report(ytest , y_pred))\n",
    "acc=metrics.accuracy_score(y,y_pred)\n",
    "print(\"accuracy : \",acc)\n",
    "all_classes = np.array(sorted(all_classes))\n",
    "# Get the probabilities for learnt classes\n",
    "prob = loaded_model.predict_proba(X)\n",
    "# Create the result matrix, where all values are initially zero\n",
    "new_prob = np.zeros((prob.shape[0], all_classes.size))\n",
    "# Set the columns corresponding to clf.classes_\n",
    "new_prob[:, all_classes.searchsorted(loaded_model.classes_)] = prob\n",
    "k_acc = metrics.top_k_accuracy_score(y,new_prob,k=1, labels=all_classes)\n",
    "print(\"top 1 accuracy : \",k_acc)\n",
    "k_acc = metrics.top_k_accuracy_score(y,new_prob,k=5, labels=all_classes)\n",
    "print(\"top 5 accuracy : \",k_acc)\n",
    "k_acc = metrics.top_k_accuracy_score(y,new_prob,k=10, labels=all_classes)\n",
    "print(\"top 10 accuracy : \",k_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The accuracies are much higher than a simple embedding based model and can be further improved with the advanced classifiers or by implementing neural network classifier head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Search Classifier/Recommender\n",
    "\n",
    "To demonstrate use of embedding search as a classifier on an entire dataframe or on a single example case, following code is re-written with modular functions. \n",
    "\n",
    "This is the same process as described in embeddings research and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define common functions used for result processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_docs_and_queries(job_embeddings, onet_embeddings, top_k=1):\n",
    "    \"\"\" \n",
    "    This method performs semantic search operation that finds top_k ONET embeddings for the given job embeddings \n",
    "    using SBERT util's semantic_search method with cosine similarity. \n",
    "    \n",
    "    Input: job_embeddings: ndarray --> List/array of input job embeddings.\n",
    "           onet_embeddings: ndarray --> List/array of input ONET embeddings.\n",
    "           top_k: int --> (Optional) top K results to return\n",
    "\n",
    "    Output: hits: list[list[{\"corpus_id\", \"score\"}]] --> Returns a list with one entry for each query. \n",
    "                             Each entry is a list of dictionaries with the keys ‘corpus_id’ (id of ONETs) and ‘score’, \n",
    "                             sorted by decreasing cosine similarity scores\n",
    "    \"\"\"\n",
    "    \n",
    "    hits = util.semantic_search(job_embeddings, onet_embeddings, top_k=top_k)\n",
    "\n",
    "    return hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_hits(all_hits,job_df, onet_embd_df):\n",
    "    \"\"\" \n",
    "    This method processes the hits returned by semantic search and maps them to corresponding inputs. \n",
    "    \n",
    "    Input: all_hits: ndarray --> List/array of hits.\n",
    "           job_df: pd.DataFrame --> Input Job Dataframe.\n",
    "           onet_embd_df: pd.DataFrame --> Input O*NET Dataframe.\n",
    "\n",
    "    Output: result_df: pd.DataFrame --> Output Dataframe with PRED_ONETS\n",
    "    \"\"\"\n",
    "    result_df = job_df.copy()\n",
    "    results = []\n",
    "    \n",
    "    for id in range(len(all_hits)):\n",
    "        hits = all_hits[id]\n",
    "        k_res = []\n",
    "        for hit in hits:\n",
    "            pred_hit = onet_embd_df[\"ONET_NAME\"][hit['corpus_id']]\n",
    "            #print(\"\\t{:.3f}\\t{}\".format(hit['score'], pred_hit))\n",
    "            k_res.append(pred_hit)\n",
    "        results.append(k_res)\n",
    "    result_df[\"PRED_ONETS\"] = pd.Series([arr for arr in results])\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_frm_file(file_path=None, data_set=None, top_k=1, save_results=False, evaluate=False, model=None, model_ckpt=None, onet_embd_path=None):\n",
    "    \"\"\"\n",
    "    Prediction function for pridicting over entire input file\n",
    "    Returns: result_df: pd.DataFrame --> Output Dataframe with PRED_ONETS\n",
    "    \"\"\"\n",
    "\n",
    "    # Get results for given dataframe\n",
    "    from_pkl = False\n",
    "    job_df = pd.DataFrame()\n",
    "    if not file_path and data_set in [\"train\", \"test\"]:\n",
    "        fname = str(data_set) + \"_data.csv\"\n",
    "        file_path = os.part.join(\"../data/raw/\",fname)\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        if file_path.endswith(\".csv\"):\n",
    "            # Take CSV file\n",
    "            # load data into DF\n",
    "            job_df = pd.read_csv(file_path)\n",
    "            from_pkl = False\n",
    "            job_df_file = None \n",
    "            # Make sure title and body present\n",
    "            if not (\"TITLE_RAW\" in job_df.columns and \"BODY\" in job_df.columns):\n",
    "                print(\"Incomplete DataFrame, please try again\")\n",
    "                return None\n",
    "        elif file_path.endswith(\".pkl\"):\n",
    "            #load df from pickle\n",
    "            from_pkl = True\n",
    "            job_df_file = file_path \n",
    "            job_df = None            \n",
    "    #Check on sample data\n",
    "    \n",
    "    #job_df = job_df.head(2)    \n",
    "    \n",
    "\n",
    "    # Get Job_Embd DF\n",
    "    job_df = get_job_embed_df_from_df(job_df=job_df, job_embd_path=job_df_file, model=model, model_ckpt=model_ckpt, save_embd=save_results)\n",
    "\n",
    "    # Get ONET Embd DF\n",
    "    onet_embd_df = get_onet_embeddings(model=model, model_ckpt=model_ckpt, onet_embd_path=onet_embd_path, save_embd=save_results)\n",
    "\n",
    "\n",
    "    all_hits = compare_docs_and_queries(np.array(job_df[\"JOB_EMBD\"].to_list()), np.array(onet_embd_df[\"ONET_EMBD\"].to_list()), top_k=top_k)\n",
    "\n",
    "    result_df = process_hits(all_hits,job_df, onet_embd_df)\n",
    "\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_frm_input_string(job_title=None, job_body=None, top_k=1, save_results=False, evaluate=False, model=None, model_ckpt=None, onet_embd_path=None):\n",
    "    \"\"\"\n",
    "    Prediction function for predicting for a single entry\n",
    "    Returns: result_df: pd.DataFrame --> Output Dataframe with PRED_ONETS\n",
    "    \"\"\"\n",
    "    # Get results for given dataframe\n",
    "    # Get Job_Embd DF\n",
    "    if job_body == \"\" or job_body is None or job_title ==\"\" or job_title is None:\n",
    "        print(\"Invalid Input, Please provide both Job Title and Body\")\n",
    "        return None\n",
    "\n",
    "    job_df = get_job_embd_df_frm_title_body(job_title, job_body)\n",
    "\n",
    "    # Get ONET Embd DF\n",
    "    onet_embd_df = get_onet_embeddings(model=model, model_ckpt=model_ckpt, onet_embd_path=onet_embd_path, save_embd=save_results)\n",
    "\n",
    "\n",
    "    all_hits = compare_docs_and_queries(np.array(job_df[\"JOB_EMBD\"].to_list()), np.array(onet_embd_df[\"ONET_EMBD\"].to_list()), top_k=top_k)\n",
    "\n",
    "    result_df = process_hits(all_hits,job_df, onet_embd_df)\n",
    "\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(job_title=None, job_body=None, top_k=1):\n",
    "    \"\"\"\n",
    "    Prediction function for predicting for a single entry and used in the prediction() pipeline\n",
    "    Returns: result: list --> Output list of predicted O*NETs\n",
    "    \"\"\"\n",
    "    onet_embd_path=\"../data/processed/embeddings/onet_custom_model_1/embd.pkl\"\n",
    "    model_ckpt = \"models/\"\n",
    "    result_df = predict_frm_input_string(job_title, job_body, model_ckpt=model_ckpt, top_k=top_k, onet_embd_path=onet_embd_path)\n",
    "\n",
    "    if result_df is None:\n",
    "        return None\n",
    "    pred_onets = result_df[\"PRED_ONETS\"].to_list()[0]\n",
    "    return pred_onets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07180061540b4c78a5507939b1746f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Jobs available:  2\n",
      "loading model from ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1234c8791af24fdfa1bda734f339f992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ONETs available:  1017\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>POSTED</th>\n",
       "      <th>TITLE_RAW</th>\n",
       "      <th>BODY</th>\n",
       "      <th>ONET_NAME</th>\n",
       "      <th>ONET</th>\n",
       "      <th>CLEANED_JOB</th>\n",
       "      <th>JOB_EMBD</th>\n",
       "      <th>PRED_ONETS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3a9bc988d77e46507f6753429dd848a816d0b9b9</td>\n",
       "      <td>2023-05-03</td>\n",
       "      <td>Executive Meeting Manager</td>\n",
       "      <td>Executive Meeting Manager Marriott La Jolla - ...</td>\n",
       "      <td>Meeting, Convention, and Event Planners</td>\n",
       "      <td>13-1121.00</td>\n",
       "      <td>[TTL] executive meeting manager [DESC] executi...</td>\n",
       "      <td>[-0.8965845, 0.21626818, 0.4062995, 0.25944906...</td>\n",
       "      <td>[Meeting, Convention, and Event Planners, Lodg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eb3a017370d55577e892ff8207a640b7d7136f31</td>\n",
       "      <td>2023-05-03</td>\n",
       "      <td>Rehabilitation Technician-Outpatient Rehab-Fle...</td>\n",
       "      <td>Rehabilitation Technician-Outpatient Rehab-Fle...</td>\n",
       "      <td>Occupational Therapy Aides</td>\n",
       "      <td>31-2012.00</td>\n",
       "      <td>[TTL] rehabilitation technician outpatient reh...</td>\n",
       "      <td>[-0.3449566, -0.016839795, -0.3339095, -0.0695...</td>\n",
       "      <td>[Rehabilitation Counselors, Occupational Thera...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         ID      POSTED  \\\n",
       "0  3a9bc988d77e46507f6753429dd848a816d0b9b9  2023-05-03   \n",
       "1  eb3a017370d55577e892ff8207a640b7d7136f31  2023-05-03   \n",
       "\n",
       "                                           TITLE_RAW  \\\n",
       "0                          Executive Meeting Manager   \n",
       "1  Rehabilitation Technician-Outpatient Rehab-Fle...   \n",
       "\n",
       "                                                BODY  \\\n",
       "0  Executive Meeting Manager Marriott La Jolla - ...   \n",
       "1  Rehabilitation Technician-Outpatient Rehab-Fle...   \n",
       "\n",
       "                                 ONET_NAME        ONET  \\\n",
       "0  Meeting, Convention, and Event Planners  13-1121.00   \n",
       "1               Occupational Therapy Aides  31-2012.00   \n",
       "\n",
       "                                         CLEANED_JOB  \\\n",
       "0  [TTL] executive meeting manager [DESC] executi...   \n",
       "1  [TTL] rehabilitation technician outpatient reh...   \n",
       "\n",
       "                                            JOB_EMBD  \\\n",
       "0  [-0.8965845, 0.21626818, 0.4062995, 0.25944906...   \n",
       "1  [-0.3449566, -0.016839795, -0.3339095, -0.0695...   \n",
       "\n",
       "                                          PRED_ONETS  \n",
       "0  [Meeting, Convention, and Event Planners, Lodg...  \n",
       "1  [Rehabilitation Counselors, Occupational Thera...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predicting output on 2 train examples without giving custom O*NET embeddings \n",
    "predict_frm_file(file_path=\"../artifacts/data_ingestion/raw_train/train_data.csv\", model_ckpt=\"models/\", top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78757b6328044943994f40a97140aa90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenght of docs:  1017\n",
      "lenght of embd:  1017\n",
      "Total ONETs available:  1017\n"
     ]
    }
   ],
   "source": [
    "# Saving O*NET embeddings for reuse\n",
    "temp_onet = get_onet_embeddings(model_ckpt=\"models/\", save_embd=True, save_path=\"data/processed/embeddings/onet_custom_model_1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e36a02596b45481684e07a7260f842eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Jobs available:  2\n",
      "Total ONETs available:  1017\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>POSTED</th>\n",
       "      <th>TITLE_RAW</th>\n",
       "      <th>BODY</th>\n",
       "      <th>ONET_NAME</th>\n",
       "      <th>ONET</th>\n",
       "      <th>CLEANED_JOB</th>\n",
       "      <th>JOB_EMBD</th>\n",
       "      <th>PRED_ONETS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3a9bc988d77e46507f6753429dd848a816d0b9b9</td>\n",
       "      <td>2023-05-03</td>\n",
       "      <td>Executive Meeting Manager</td>\n",
       "      <td>Executive Meeting Manager Marriott La Jolla - ...</td>\n",
       "      <td>Meeting, Convention, and Event Planners</td>\n",
       "      <td>13-1121.00</td>\n",
       "      <td>[TTL] executive meeting manager [DESC] executi...</td>\n",
       "      <td>[-0.8965845, 0.21626818, 0.4062995, 0.25944906...</td>\n",
       "      <td>[Meeting, Convention, and Event Planners, Lodg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eb3a017370d55577e892ff8207a640b7d7136f31</td>\n",
       "      <td>2023-05-03</td>\n",
       "      <td>Rehabilitation Technician-Outpatient Rehab-Fle...</td>\n",
       "      <td>Rehabilitation Technician-Outpatient Rehab-Fle...</td>\n",
       "      <td>Occupational Therapy Aides</td>\n",
       "      <td>31-2012.00</td>\n",
       "      <td>[TTL] rehabilitation technician outpatient reh...</td>\n",
       "      <td>[-0.3449566, -0.016839795, -0.3339095, -0.0695...</td>\n",
       "      <td>[Rehabilitation Counselors, Occupational Thera...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         ID      POSTED  \\\n",
       "0  3a9bc988d77e46507f6753429dd848a816d0b9b9  2023-05-03   \n",
       "1  eb3a017370d55577e892ff8207a640b7d7136f31  2023-05-03   \n",
       "\n",
       "                                           TITLE_RAW  \\\n",
       "0                          Executive Meeting Manager   \n",
       "1  Rehabilitation Technician-Outpatient Rehab-Fle...   \n",
       "\n",
       "                                                BODY  \\\n",
       "0  Executive Meeting Manager Marriott La Jolla - ...   \n",
       "1  Rehabilitation Technician-Outpatient Rehab-Fle...   \n",
       "\n",
       "                                 ONET_NAME        ONET  \\\n",
       "0  Meeting, Convention, and Event Planners  13-1121.00   \n",
       "1               Occupational Therapy Aides  31-2012.00   \n",
       "\n",
       "                                         CLEANED_JOB  \\\n",
       "0  [TTL] executive meeting manager [DESC] executi...   \n",
       "1  [TTL] rehabilitation technician outpatient reh...   \n",
       "\n",
       "                                            JOB_EMBD  \\\n",
       "0  [-0.8965845, 0.21626818, 0.4062995, 0.25944906...   \n",
       "1  [-0.3449566, -0.016839795, -0.3339095, -0.0695...   \n",
       "\n",
       "                                          PRED_ONETS  \n",
       "0  [Meeting, Convention, and Event Planners, Lodg...  \n",
       "1  [Rehabilitation Counselors, Occupational Thera...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predicting again with saved O*NETs\n",
    "predict_frm_file(file_path=\"../artifacts/data_ingestion/raw_train/train_data.csv\", model_ckpt=\"models/\", top_k=3, onet_embd_path=\"data/processed/embeddings/onet_custom_model_1/embd.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting for sample train dataframe with 5 examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to Job DF Given\n",
      "Total Jobs available:  5\n",
      "Total ONETs available:  1017\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE_RAW</th>\n",
       "      <th>BODY</th>\n",
       "      <th>CLEANED_JOB</th>\n",
       "      <th>JOB_EMBD</th>\n",
       "      <th>PRED_ONETS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>executive meeting manager</td>\n",
       "      <td>[DESC] executive meeting manager marriott la j...</td>\n",
       "      <td>[TTL] executive meeting manager [DESC] executi...</td>\n",
       "      <td>[-0.8965845, 0.21626818, 0.4062995, 0.25944906...</td>\n",
       "      <td>[Meeting, Convention, and Event Planners, Lodg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rehabilitation technician outpatient rehab fle...</td>\n",
       "      <td>[DESC] rehabilitation technician outpatient re...</td>\n",
       "      <td>[TTL] rehabilitation technician outpatient reh...</td>\n",
       "      <td>[-0.3449566, -0.016839795, -0.3339095, -0.0695...</td>\n",
       "      <td>[Rehabilitation Counselors, Occupational Thera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>office bookkeeping assistant</td>\n",
       "      <td>[DESC] office bookkeeping assistant santa barb...</td>\n",
       "      <td>[TTL] office bookkeeping assistant [DESC] offi...</td>\n",
       "      <td>[-0.4091167, 1.4821604, 0.52472407, -0.1098092...</td>\n",
       "      <td>[Office Clerks, General, Bookkeeping, Accounti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>administrative support coordinator va remote</td>\n",
       "      <td>[DESC] find jobs administrative support coordi...</td>\n",
       "      <td>[TTL] administrative support coordinator va re...</td>\n",
       "      <td>[-0.81933033, 0.6742432, 0.61316764, -0.277764...</td>\n",
       "      <td>[Office and Administrative Support Workers, Al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>receptionist administrative assistant</td>\n",
       "      <td>[DESC] receptionist administrative assistant b...</td>\n",
       "      <td>[TTL] receptionist administrative assistant [D...</td>\n",
       "      <td>[-0.3198364, 1.0830945, 0.35040185, -0.0614275...</td>\n",
       "      <td>[Secretaries and Administrative Assistants, Ex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           TITLE_RAW  \\\n",
       "0                          executive meeting manager   \n",
       "1  rehabilitation technician outpatient rehab fle...   \n",
       "2                       office bookkeeping assistant   \n",
       "3       administrative support coordinator va remote   \n",
       "4              receptionist administrative assistant   \n",
       "\n",
       "                                                BODY  \\\n",
       "0  [DESC] executive meeting manager marriott la j...   \n",
       "1  [DESC] rehabilitation technician outpatient re...   \n",
       "2  [DESC] office bookkeeping assistant santa barb...   \n",
       "3  [DESC] find jobs administrative support coordi...   \n",
       "4  [DESC] receptionist administrative assistant b...   \n",
       "\n",
       "                                         CLEANED_JOB  \\\n",
       "0  [TTL] executive meeting manager [DESC] executi...   \n",
       "1  [TTL] rehabilitation technician outpatient reh...   \n",
       "2  [TTL] office bookkeeping assistant [DESC] offi...   \n",
       "3  [TTL] administrative support coordinator va re...   \n",
       "4  [TTL] receptionist administrative assistant [D...   \n",
       "\n",
       "                                            JOB_EMBD  \\\n",
       "0  [-0.8965845, 0.21626818, 0.4062995, 0.25944906...   \n",
       "1  [-0.3449566, -0.016839795, -0.3339095, -0.0695...   \n",
       "2  [-0.4091167, 1.4821604, 0.52472407, -0.1098092...   \n",
       "3  [-0.81933033, 0.6742432, 0.61316764, -0.277764...   \n",
       "4  [-0.3198364, 1.0830945, 0.35040185, -0.0614275...   \n",
       "\n",
       "                                          PRED_ONETS  \n",
       "0  [Meeting, Convention, and Event Planners, Lodg...  \n",
       "1  [Rehabilitation Counselors, Occupational Thera...  \n",
       "2  [Office Clerks, General, Bookkeeping, Accounti...  \n",
       "3  [Office and Administrative Support Workers, Al...  \n",
       "4  [Secretaries and Administrative Assistants, Ex...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_5_df = predict_frm_file(file_path=\"data/processed/embeddings/job/custom_model_1/train/5/embd.pkl\", model_ckpt=\"models/\", top_k=2, onet_embd_path=\"data/processed/embeddings/onet_custom_model_1/embd.pkl\")\n",
    "temp_5_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "following code is copied from 00_02_embeddings.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Semantic search on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Test DataLoader from saved dataset\n",
    "test_examples = []\n",
    "test_data = dataset['test']\n",
    "\n",
    "n_examples = dataset['test'].num_rows\n",
    "test_queries = {}\n",
    "test_relevant_docs = {}\n",
    "\n",
    "for i in range(n_examples):\n",
    "  example = test_data[i]\n",
    "  test_examples.append(InputExample(texts=[example['job_post'], example['onet_name']]))\n",
    "  test_queries[str(i)] = example['job_post']\n",
    "  test_relevant_docs[str(i)] = onet_to_id_dict[example[\"onet_name\"]]\n",
    "print(f\"We have a {type(test_examples)} of length {len(test_examples)} containing {type(test_examples[0])}'s.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries_ids = []\n",
    "for qid in test_queries:\n",
    "    if qid in test_relevant_docs and len(test_relevant_docs[qid]) > 0:\n",
    "        test_queries_ids.append(qid)\n",
    "\n",
    "test_queries = [test_queries[qid] for qid in test_queries_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model as it is\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e2194abb704ad19840cbcaba2e585c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_q_embd = get_embd(test_queries, model=sbert_model)\n",
    "test_hits = util.semantic_search(test_q_embd, np.array(onet_embd_df[\"ONET_EMBD\"].to_list()), top_k=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom code to calculate Performance metrics\n",
    "\n",
    "acc_at_k = [1,5,10]\n",
    "num_hits_at_k = {k:0 for k in acc_at_k}\n",
    "\n",
    "precision_recall_at_k = [1,5,10]\n",
    "precisions_at_k = {k:[] for k in precision_recall_at_k}\n",
    "recall_at_k = {k:[] for k in precision_recall_at_k}\n",
    "\n",
    "mrr_at_k = [1,5,10]\n",
    "MRR = {k:0 for k in mrr_at_k}\n",
    "\n",
    "\n",
    "for test_qid in range(len(test_hits)):\n",
    "\n",
    "    qid = test_queries_ids[test_qid]\n",
    "    # Sort scores\n",
    "    top_hits = test_hits[test_qid]\n",
    "    query_relevant_docs = [int(test_relevant_docs[qid])]\n",
    "\n",
    "    # Accuracy@k - We count the result correct, if at least one relevant doc is accross the top-k documents\n",
    "    for k_val in acc_at_k:\n",
    "        for hit in top_hits[0:k_val]:\n",
    "            if hit['corpus_id'] in query_relevant_docs:\n",
    "                num_hits_at_k[k_val] += 1\n",
    "                break\n",
    "\n",
    "    # Precision and Recall@k\n",
    "    for k_val in precision_recall_at_k:\n",
    "        num_correct = 0\n",
    "        for hit in top_hits[0:k_val]:\n",
    "            if hit['corpus_id'] in query_relevant_docs:\n",
    "                num_correct += 1\n",
    "\n",
    "        precisions_at_k[k_val].append(num_correct / k_val)\n",
    "        recall_at_k[k_val].append(num_correct / len(query_relevant_docs))\n",
    "\n",
    "    # MRR@k\n",
    "    for k_val in mrr_at_k:\n",
    "        for rank, hit in enumerate(top_hits[0:k_val]):\n",
    "            if hit['corpus_id'] in query_relevant_docs:\n",
    "                MRR[k_val] += 1.0 / (rank + 1)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy@k {1: 0.5129533678756477, 5: 0.7461139896373057, 10: 0.8134715025906736}\n",
      "precision@k {1: 0.5129533678756477, 5: 0.14922279792746113, 10: 0.08134715025906736}\n",
      "recall@k {1: 0.5129533678756477, 5: 0.7461139896373057, 10: 0.8134715025906736}\n",
      "mrr@k {1: 0.5129533678756477, 5: 0.6051813471502591, 10: 0.6137326260383255}\n"
     ]
    }
   ],
   "source": [
    "for k in num_hits_at_k:\n",
    "    num_hits_at_k[k] /= len(test_queries)\n",
    "\n",
    "for k in precisions_at_k:\n",
    "    precisions_at_k[k] = np.mean(precisions_at_k[k])\n",
    "\n",
    "for k in recall_at_k:\n",
    "    recall_at_k[k] = np.mean(recall_at_k[k])\n",
    "\n",
    "for k in MRR:\n",
    "    MRR[k] /= len(test_queries)\n",
    "\n",
    "op_dict =  {'accuracy@k': num_hits_at_k, 'precision@k': precisions_at_k, 'recall@k': recall_at_k, 'mrr@k': MRR}\n",
    "for key,val in op_dict.items():\n",
    "    print(key, val)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fetch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
